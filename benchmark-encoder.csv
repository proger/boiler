,batch_size,latency,latency_std,loss,loss_std,device,dtype,type,size,autocast,reason
0,1,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
1,2,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
2,3,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
3,4,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
4,5,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
5,6,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
6,7,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
7,8,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
8,9,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
9,10,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
10,11,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
11,12,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
12,13,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
13,14,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
14,15,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
15,16,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
16,24,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
17,32,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
18,64,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
19,1,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
20,2,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
21,3,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
22,4,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
23,5,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
24,6,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
25,7,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
26,8,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
27,9,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
28,10,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
29,11,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
30,12,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
31,13,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
32,14,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
33,15,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
34,16,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
35,24,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
36,32,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
37,64,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
38,1,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
39,2,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
40,3,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
41,4,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
42,5,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
43,6,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
44,7,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
45,8,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
46,9,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
47,10,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
48,11,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
49,12,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
50,13,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
51,14,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
52,15,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
53,16,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
54,24,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
55,32,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
56,64,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
57,1,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
58,2,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
59,3,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
60,4,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
61,5,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
62,6,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
63,7,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
64,8,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
65,9,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
66,10,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
67,11,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
68,12,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
69,13,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
70,14,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
71,15,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
72,16,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
73,24,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
74,32,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
75,64,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
76,1,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
77,2,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
78,3,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
79,4,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
80,5,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
81,6,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
82,7,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
83,8,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
84,9,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
85,10,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
86,11,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
87,12,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
88,13,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
89,14,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
90,15,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
91,16,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
92,24,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
93,32,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
94,64,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
95,1,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
96,2,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
97,3,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
98,4,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
99,5,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
100,6,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
101,7,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
102,8,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
103,9,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
104,10,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
105,11,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
106,12,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
107,13,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
108,14,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
109,15,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
110,16,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
111,24,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
112,32,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
113,64,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
114,1,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
115,2,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
116,3,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
117,4,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
118,5,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
119,6,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
120,7,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
121,8,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
122,9,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
123,10,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
124,11,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
125,12,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
126,13,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
127,14,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
128,15,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
129,16,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
130,24,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
131,32,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
132,64,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
133,1,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
134,2,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
135,3,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
136,4,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
137,5,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
138,6,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
139,7,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
140,8,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
141,9,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
142,10,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
143,11,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
144,12,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
145,13,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
146,14,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
147,15,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
148,16,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
149,24,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
150,32,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
151,64,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
152,1,0.007764704525470734,0.00070061010774225,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
153,2,0.007698577828705311,0.00018161618208978325,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
154,3,0.00798680167645216,0.00018219379126094282,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
155,4,0.007962910458445549,0.00011404958786442876,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
156,5,0.007855098694562912,0.00013095517351757735,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
157,6,0.007776002399623394,0.0003114266146440059,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
158,7,0.007952800020575523,9.994879656005651e-05,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
159,8,0.008269930258393288,0.00012226785474922508,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
160,9,0.008626540191471577,0.00010332382225897163,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
161,10,0.00897043477743864,9.91349370451644e-05,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
162,11,0.009278890676796436,6.600289634661749e-05,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
163,12,0.009586155414581299,7.781471504131332e-05,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
164,13,0.009882211685180664,6.847856275271624e-05,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
165,14,0.010131953284144402,6.769854371668771e-05,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
166,15,0.010610821656882763,7.28017621440813e-05,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
167,16,0.010763880796730518,6.305327406153083e-05,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
168,24,0.013450002297759056,5.69104086025618e-05,0.00033430257462896407,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
169,32,0.016020523384213448,5.375430919229984e-05,0.0005551017820835114,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
170,64,0.02989770472049713,0.00014759543410036713,0.0005358336493372917,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
171,96,0.042168743908405304,0.00015355653886217624,0.00045135742402635515,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
172,128,0.055106841027736664,0.00019986859115306288,0.0004587867297232151,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
173,160,0.06807748228311539,0.0003020517178811133,0.0005580622819252312,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
174,192,0.08050611615180969,0.0003726532740984112,0.0004650518822018057,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
175,256,0.10653536021709442,0.0005500372499227524,0.0004667195025831461,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
176,512,0.21536926925182343,0.0019308441551402211,0.0004667195025831461,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
177,1024,0.4296944737434387,0.0027787708677351475,0.0004667195025831461,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
178,2048,,,,,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,CUDA out of memory. Tried to allocate 4.00 GiB (GPU 0; 10.91 GiB total capacity; 6.09 GiB already allocated; 3.09 GiB free; 7.02 GiB reserved in total by PyTorch)
179,4096,,,,,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,CUDA out of memory. Tried to allocate 4.01 GiB (GPU 0; 10.91 GiB total capacity; 8.09 GiB already allocated; 92.25 MiB free; 10.02 GiB reserved in total by PyTorch)
180,1,0.007609643042087555,0.002202955074608326,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
181,2,0.007031777407974005,0.0012601326452568173,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
182,3,0.006722100079059601,0.00022848018852528185,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
183,4,0.006731180939823389,0.0002891993790399283,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
184,5,0.0068140095099806786,0.00020712871628347784,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
185,6,0.00708883348852396,0.00010250572086079046,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
186,7,0.007304987404495478,9.355406655231491e-05,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
187,8,0.007472775876522064,8.159725985024124e-05,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
188,9,0.0077368272468447685,0.00010476370516698807,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
189,10,0.00793386995792389,8.962595165940002e-05,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
190,11,0.008150149136781693,0.00012234519817866385,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
191,12,0.008343616500496864,6.24061722191982e-05,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
192,13,0.008570598438382149,6.340222898870707e-05,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
193,14,0.008722054772078991,6.724234845023602e-05,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
194,15,0.011114148423075676,5.8149285905528814e-05,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
195,16,0.011185665614902973,6.503654731204733e-05,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
196,24,0.013194933533668518,0.00012587715173140168,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
197,32,0.014977781102061272,0.00010194304923061281,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
198,64,0.02600761130452156,8.52670636959374e-05,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
199,96,0.03393002599477768,0.00015426156460307539,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
200,128,0.04411647468805313,0.00024700205540284514,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
201,160,0.05437464267015457,0.00020269890956114978,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
202,192,0.06349675357341766,0.0004840448673348874,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
203,256,0.08450068533420563,0.0002549154742155224,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
204,512,0.1689073145389557,0.00046780225238762796,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
205,1024,0.3383966088294983,0.0018498037243261933,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
206,2048,,,,,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,CUDA out of memory. Tried to allocate 4.00 GiB (GPU 0; 10.91 GiB total capacity; 6.08 GiB already allocated; 3.09 GiB free; 7.02 GiB reserved in total by PyTorch)
207,4096,,,,,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,CUDA out of memory. Tried to allocate 4.01 GiB (GPU 0; 10.91 GiB total capacity; 8.08 GiB already allocated; 94.25 MiB free; 10.02 GiB reserved in total by PyTorch)
208,1,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
209,2,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
210,3,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
211,4,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
212,5,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
213,6,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
214,7,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
215,8,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
216,9,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
217,10,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
218,11,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
219,12,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
220,13,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
221,14,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
222,15,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
223,16,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
224,24,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
225,32,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
226,64,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
227,96,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
228,128,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
229,160,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
230,192,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
231,256,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
232,512,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
233,1024,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
234,2048,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/encoder.py"", line 29, in forward
    def forward(self, batch):
        return self.model.encode_bag_t(self.fft(batch).unsqueeze(1), normalize=True)[0]
                                       ~~~~~~~~ <--- HERE
  File ""/home/proger/boiler/boiler/mel.py"", line 39, in forward
        p = (self.n_fft - self.hop_length) // 2
        audio = F.pad(audio, (p, p), ""reflect"").squeeze(1)
        fft = torch.stft(
              ~~~~~~~~~~ <--- HERE
            audio,
            n_fft=self.n_fft,
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/functional.py"", line 515, in stft
        input = F.pad(input.view(extended_shape), (pad, pad), pad_mode)
        input = input.view(input.shape[-signal_dim:])
    return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore
           ~~~~~~~~ <--- HERE
                    normalized, onesided, return_complex)
RuntimeError: CUDA out of memory. Tried to allocate 4.00 GiB (GPU 0; 10.91 GiB total capacity; 6.09 GiB already allocated; 3.09 GiB free; 7.03 GiB reserved in total by PyTorch)
"
235,4096,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/encoder.py"", line 29, in forward
    def forward(self, batch):
        return self.model.encode_bag_t(self.fft(batch).unsqueeze(1), normalize=True)[0]
                                       ~~~~~~~~ <--- HERE
  File ""/home/proger/boiler/boiler/mel.py"", line 39, in forward
        p = (self.n_fft - self.hop_length) // 2
        audio = F.pad(audio, (p, p), ""reflect"").squeeze(1)
        fft = torch.stft(
              ~~~~~~~~~~ <--- HERE
            audio,
            n_fft=self.n_fft,
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/functional.py"", line 515, in stft
        input = F.pad(input.view(extended_shape), (pad, pad), pad_mode)
        input = input.view(input.shape[-signal_dim:])
    return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore
           ~~~~~~~~ <--- HERE
                    normalized, onesided, return_complex)
RuntimeError: CUDA out of memory. Tried to allocate 4.01 GiB (GPU 0; 10.91 GiB total capacity; 8.09 GiB already allocated; 90.25 MiB free; 10.03 GiB reserved in total by PyTorch)
"
236,1,0.006287636701017618,0.0010029213735833764,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
237,2,0.0058167241513729095,0.00022103128139860928,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
238,3,0.00583270937204361,0.00016000901814550161,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
239,4,0.006061720661818981,0.0004625718283932656,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
240,5,0.006176882889121771,9.53057678998448e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
241,6,0.0064798397943377495,4.9865444452734664e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
242,7,0.006668460555374622,4.666709355660714e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
243,8,0.006859915796667337,4.785558121511713e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
244,9,0.007098165340721607,4.626738518709317e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
245,10,0.007308614440262318,3.7595982576021925e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
246,11,0.007509925402700901,3.8393820432247594e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
247,12,0.00774712348356843,3.493381154839881e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
248,13,0.00796513631939888,3.9092221413739026e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
249,14,0.008112219162285328,3.730853495653719e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
250,15,0.010508771054446697,3.5752593248616904e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
251,16,0.010599561966955662,4.674712545238435e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
252,24,0.012550009414553642,3.49702822859399e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
253,32,0.01432269811630249,3.080033275182359e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
254,64,0.025237509980797768,0.00019959932251367718,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
255,96,0.03315351530909538,0.00012137783778598532,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
256,128,0.04320065304636955,0.00014373159501701593,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
257,160,0.05318746715784073,0.00023099292593542486,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
258,192,0.06242648512125015,0.0003631682775449008,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
259,256,0.08304201066493988,0.0003302461700513959,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
260,512,0.1685577929019928,0.0010020768968388438,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
261,1024,0.3319198191165924,0.0016110409051179886,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
262,2048,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/encoder.py"", line 29, in forward
    def forward(self, batch):
        return self.model.encode_bag_t(self.fft(batch).unsqueeze(1), normalize=True)[0]
                                       ~~~~~~~~ <--- HERE
  File ""/home/proger/boiler/boiler/mel.py"", line 39, in forward
        p = (self.n_fft - self.hop_length) // 2
        audio = F.pad(audio, (p, p), ""reflect"").squeeze(1)
        fft = torch.stft(
              ~~~~~~~~~~ <--- HERE
            audio,
            n_fft=self.n_fft,
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/functional.py"", line 515, in stft
        input = F.pad(input.view(extended_shape), (pad, pad), pad_mode)
        input = input.view(input.shape[-signal_dim:])
    return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore
           ~~~~~~~~ <--- HERE
                    normalized, onesided, return_complex)
RuntimeError: CUDA out of memory. Tried to allocate 4.00 GiB (GPU 0; 10.91 GiB total capacity; 6.08 GiB already allocated; 3.09 GiB free; 7.02 GiB reserved in total by PyTorch)
"
263,4096,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/encoder.py"", line 29, in forward
    def forward(self, batch):
        return self.model.encode_bag_t(self.fft(batch).unsqueeze(1), normalize=True)[0]
                                       ~~~~~~~~ <--- HERE
  File ""/home/proger/boiler/boiler/mel.py"", line 39, in forward
        p = (self.n_fft - self.hop_length) // 2
        audio = F.pad(audio, (p, p), ""reflect"").squeeze(1)
        fft = torch.stft(
              ~~~~~~~~~~ <--- HERE
            audio,
            n_fft=self.n_fft,
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/functional.py"", line 515, in stft
        input = F.pad(input.view(extended_shape), (pad, pad), pad_mode)
        input = input.view(input.shape[-signal_dim:])
    return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore
           ~~~~~~~~ <--- HERE
                    normalized, onesided, return_complex)
RuntimeError: CUDA out of memory. Tried to allocate 4.01 GiB (GPU 0; 10.91 GiB total capacity; 8.08 GiB already allocated; 92.25 MiB free; 10.02 GiB reserved in total by PyTorch)
"
264,1,0.006935637444257736,0.00015824416186660528,0.005705833435058594,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
265,2,0.006731766276061535,0.0002153914247173816,0.002852916717529297,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
266,3,0.007349830120801926,0.0016230074688792229,0.0019019445171579719,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
267,4,0.007227279245853424,6.943450716789812e-05,0.0014264583587646484,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
268,5,0.007580834440886974,7.301889854716137e-05,0.0011411666637286544,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
269,6,0.008022141642868519,7.888513937359676e-05,0.0009509722585789859,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
270,7,0.008350771851837635,6.338734965538606e-05,0.0008151190122589469,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
271,8,0.008706760592758656,7.30440515326336e-05,0.013246290385723114,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
272,9,0.00910174660384655,6.154309812700376e-05,0.01177448034286499,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
273,10,0.009518369100987911,6.712140020681545e-05,0.010597032494843006,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
274,11,0.009915772825479507,7.616192306159064e-05,0.012545612640678883,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
275,12,0.010322162881493568,0.00018502214516047388,0.011500145308673382,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
276,13,0.010568023659288883,6.164790102047846e-05,0.010615518316626549,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
277,14,0.010868162848055363,6.398163532139733e-05,0.01055060513317585,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
278,15,0.011395384557545185,6.692492752335966e-05,0.009847232140600681,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
279,16,0.01158574502915144,6.534322164952755e-05,0.009231779724359512,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
280,24,0.014672878198325634,6.6138687543571e-05,0.007011006120592356,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
281,32,0.017600160092115402,5.1720755436690524e-05,0.0061548613011837006,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
282,64,0.03298964723944664,3.633191954577342e-05,0.010534507222473621,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
283,96,0.046847786754369736,0.00015074899420142174,0.015698133036494255,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
284,128,0.06118125841021538,0.0002772608131635934,0.016236258670687675,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
285,160,0.07568968832492828,0.00030547589994966984,0.013809862546622753,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
286,192,0.08956277370452881,0.0004490242572501302,0.015298736281692982,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
287,256,0.11941244453191757,0.0006169762345962226,0.013329831883311272,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
288,512,0.24006140232086182,0.0020488055888563395,0.013329831883311272,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
289,1024,0.4807325303554535,0.003365895012393594,0.013329831883311272,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
290,2048,0.8738530874252319,0.007418847177177668,0.013217763975262642,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
291,4096,,,,,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,CUDA out of memory. Tried to allocate 8.01 GiB (GPU 0; 10.91 GiB total capacity; 6.06 GiB already allocated; 2.09 GiB free; 8.02 GiB reserved in total by PyTorch)
292,1,0.006866308860480785,0.00017762667266651988,0.0,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
293,2,0.006592612713575363,0.00015431235078722239,0.0,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
294,3,0.0072332946583628654,0.0012514450354501605,0.0,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
295,4,0.007220406085252762,8.485814032610506e-05,0.0,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
296,5,0.007599527947604656,0.0001382753107463941,0.0,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
297,6,0.007996289059519768,6.132546695880592e-05,0.0,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
298,7,0.008316338062286377,7.378962618531659e-05,0.0,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
299,8,0.008670037612318993,5.814037285745144e-05,0.01253306120634079,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
300,9,0.00905486661940813,5.689436147804372e-05,0.011140499264001846,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
301,10,0.009471071884036064,5.591070294030942e-05,0.010026449337601662,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
302,11,0.009874134324491024,7.349599036388099e-05,0.012026900425553322,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
303,12,0.010172401554882526,5.830152804264799e-05,0.01102465856820345,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
304,13,0.010557034984230995,5.917318048886955e-05,0.010176608338952065,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
305,14,0.010852919891476631,5.656171197188087e-05,0.010143046267330647,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
306,15,0.011380956508219242,6.560164911206812e-05,0.009466842748224735,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
307,16,0.01158134825527668,6.269306322792545e-05,0.00887516513466835,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
308,24,0.014726576395332813,7.656946399947628e-05,0.006773263216018677,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
309,32,0.01760144904255867,5.0893457228085026e-05,0.0059765540063381195,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
310,64,0.03301193565130234,9.021878940984607e-05,0.010683773085474968,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
311,96,0.046786028891801834,9.87848688964732e-05,0.015728043392300606,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
312,128,0.06104106456041336,0.00031162911909632385,0.017093608155846596,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
313,160,0.07571490108966827,0.00040357743273489177,0.01444715540856123,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
314,192,0.08930443227291107,0.0003877278068102896,0.015923447906970978,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
315,256,0.11890797317028046,0.0006734701455570757,0.013798365369439125,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
316,512,0.2397056519985199,0.0019030168186873198,0.013798365369439125,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
317,1024,0.48036208748817444,0.003672617254778743,0.013798365369439125,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
318,2048,0.8768582344055176,0.008242480456829071,0.013783414848148823,0.0,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
319,4096,,,,,cuda,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,CUDA out of memory. Tried to allocate 8.01 GiB (GPU 0; 10.91 GiB total capacity; 6.06 GiB already allocated; 2.09 GiB free; 8.02 GiB reserved in total by PyTorch)
320,1,,,,,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
321,2,,,,,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
322,3,,,,,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
323,4,,,,,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
324,5,,,,,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
325,6,,,,,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
326,7,,,,,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
327,8,,,,,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
328,9,,,,,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
329,10,,,,,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
330,11,,,,,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
331,12,,,,,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
332,13,,,,,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
333,14,,,,,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
334,15,,,,,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
335,16,,,,,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
336,24,,,,,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
337,32,,,,,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
338,64,,,,,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
339,96,,,,,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
340,128,,,,,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
341,160,,,,,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
342,192,,,,,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
343,256,,,,,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
344,512,,,,,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
345,1024,,,,,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
346,2048,,,,,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
347,4096,,,,,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/encoder.py"", line 29, in forward
    def forward(self, batch):
        return self.model.encode_bag_t(self.fft(batch).unsqueeze(1), normalize=True)[0]
                                       ~~~~~~~~ <--- HERE
  File ""/home/proger/boiler/boiler/mel.py"", line 39, in forward
        p = (self.n_fft - self.hop_length) // 2
        audio = F.pad(audio, (p, p), ""reflect"").squeeze(1)
        fft = torch.stft(
              ~~~~~~~~~~ <--- HERE
            audio,
            n_fft=self.n_fft,
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/functional.py"", line 515, in stft
        input = F.pad(input.view(extended_shape), (pad, pad), pad_mode)
        input = input.view(input.shape[-signal_dim:])
    return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore
           ~~~~~~~~ <--- HERE
                    normalized, onesided, return_complex)
RuntimeError: CUDA out of memory. Tried to allocate 8.01 GiB (GPU 0; 10.91 GiB total capacity; 6.06 GiB already allocated; 2.10 GiB free; 8.02 GiB reserved in total by PyTorch)
"
348,1,0.005910834763199091,0.00010387766815256327,0.0,0.0,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
349,2,0.006175377406179905,0.0012359105749055743,0.0,0.0,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
350,3,0.006242854055017233,0.00010191406181547791,0.0,0.0,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
351,4,0.006576221436262131,5.0653397920541465e-05,0.0,0.0,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
352,5,0.006923207547515631,5.097677421872504e-05,0.0,0.0,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
353,6,0.00735440943390131,3.842146179522388e-05,0.0,0.0,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
354,7,0.007671483792364597,4.096389966434799e-05,0.0,0.0,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
355,8,0.00801863707602024,4.67477657366544e-05,0.01253306120634079,0.0,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
356,9,0.008409399539232254,4.793178231921047e-05,0.011140499264001846,0.0,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
357,10,0.008823425509035587,3.7055629945825785e-05,0.010026449337601662,0.0,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
358,11,0.009193173609673977,4.584215275826864e-05,0.012026900425553322,0.0,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
359,12,0.009502679109573364,5.1555223762989044e-05,0.01102465856820345,0.0,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
360,13,0.009849226102232933,3.77869546355214e-05,0.010176608338952065,0.0,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
361,14,0.010173054412007332,6.371217023115605e-05,0.010143046267330647,0.0,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
362,15,0.010678146034479141,3.661204027594067e-05,0.009466842748224735,0.0,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
363,16,0.010861051268875599,3.676763299154118e-05,0.00887516513466835,0.0,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
364,24,0.013874689117074013,3.3284188248217106e-05,0.006773263216018677,0.0,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
365,32,0.01672963798046112,4.669152622227557e-05,0.0059765540063381195,0.0,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
366,64,0.03179265186190605,2.6285659259883687e-05,0.010683773085474968,0.0,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
367,96,0.04521898180246353,2.5339155399706215e-05,0.015728043392300606,0.0,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
368,128,0.05908733606338501,6.110252434154972e-05,0.017093608155846596,0.0,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
369,160,0.07360194623470306,0.0002626091009005904,0.01444715540856123,0.0,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
370,192,0.08706750720739365,0.0004018274776171893,0.015923447906970978,0.0,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
371,256,0.1167178750038147,0.0009399297414347529,0.013798365369439125,0.0,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
372,512,0.23630556464195251,0.0019996282644569874,0.013798365369439125,0.0,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
373,1024,0.47089704871177673,0.0031227131839841604,0.013798365369439125,0.0,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
374,2048,0.8535072207450867,0.0072596692480146885,0.013783414848148823,0.0,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
375,4096,,,,,cuda,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/encoder.py"", line 29, in forward
    def forward(self, batch):
        return self.model.encode_bag_t(self.fft(batch).unsqueeze(1), normalize=True)[0]
                                       ~~~~~~~~ <--- HERE
  File ""/home/proger/boiler/boiler/mel.py"", line 39, in forward
        p = (self.n_fft - self.hop_length) // 2
        audio = F.pad(audio, (p, p), ""reflect"").squeeze(1)
        fft = torch.stft(
              ~~~~~~~~~~ <--- HERE
            audio,
            n_fft=self.n_fft,
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/functional.py"", line 515, in stft
        input = F.pad(input.view(extended_shape), (pad, pad), pad_mode)
        input = input.view(input.shape[-signal_dim:])
    return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore
           ~~~~~~~~ <--- HERE
                    normalized, onesided, return_complex)
RuntimeError: CUDA out of memory. Tried to allocate 8.01 GiB (GPU 0; 10.91 GiB total capacity; 6.06 GiB already allocated; 2.10 GiB free; 8.02 GiB reserved in total by PyTorch)
"
376,1,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
377,2,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
378,3,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
379,4,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
380,5,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
381,6,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
382,7,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
383,8,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
384,9,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
385,10,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
386,11,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
387,12,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
388,13,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
389,14,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
390,15,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
391,16,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
392,24,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
393,32,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
394,64,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,"""reflection_pad1d"" not implemented for 'Half'"
395,1,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
396,2,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
397,3,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
398,4,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
399,5,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
400,6,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
401,7,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
402,8,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
403,9,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
404,10,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
405,11,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
406,12,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
407,13,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
408,14,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
409,15,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
410,16,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
411,24,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
412,32,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
413,64,,,,,cpu,torch.float16,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,"""reflection_pad1d"" not implemented for 'Half'"
414,1,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
415,2,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
416,3,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
417,4,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
418,5,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
419,6,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
420,7,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
421,8,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
422,9,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
423,10,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
424,11,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
425,12,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
426,13,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
427,14,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
428,15,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
429,16,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
430,24,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
431,32,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
432,64,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
433,1,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
434,2,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
435,3,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
436,4,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
437,5,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
438,6,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
439,7,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
440,8,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
441,9,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
442,10,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
443,11,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
444,12,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
445,13,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
446,14,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
447,15,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
448,16,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
449,24,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
450,32,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
451,64,,,,,cpu,torch.float16,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 3559, in forward
            assert len(pad) == 2, '3D tensors expect 2 values for padding'
            if mode == 'reflect':
                return torch._C._nn.reflection_pad1d(input, pad)
                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
            elif mode == 'replicate':
                return torch._C._nn.replication_pad1d(input, pad)
RuntimeError: ""reflection_pad1d"" not implemented for 'Half'
"
452,1,0.007665451616048813,0.0005038673989474773,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
453,2,0.0075147985480725765,0.0003180906060151756,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
454,3,0.006990473717451096,0.00024159201711881906,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
455,4,0.007019103970378637,0.00012980465544387698,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
456,5,0.007284905761480331,0.00011815362086053938,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
457,6,0.007673929445445538,0.00010283150913892314,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
458,7,0.00796093326061964,9.193019650410861e-05,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
459,8,0.008240917697548866,0.00012907285417895764,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
460,9,0.008634150959551334,0.00013894583389628679,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
461,10,0.008958813734352589,0.00011104834993602708,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
462,11,0.009253798983991146,7.245646702358499e-05,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
463,12,0.009542645886540413,6.887035851832479e-05,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
464,13,0.009860248304903507,8.835984044708312e-05,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
465,14,0.0100978072732687,6.946975918253884e-05,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
466,15,0.010579658672213554,5.694774154108018e-05,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
467,16,0.010726323351264,7.076649490045384e-05,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
468,24,0.013406695798039436,6.029307405697182e-05,0.00033430257462896407,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
469,32,0.015984898433089256,0.00011535261000972241,0.0005551017820835114,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
470,64,0.029955267906188965,0.00015012592484708875,0.0005358336493372917,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
471,96,0.04212550073862076,0.0001624641299713403,0.00045135742402635515,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
472,128,0.05499895662069321,0.00020115541701670736,0.0004587867297232151,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
473,160,0.06800176948308945,0.00030575876007787883,0.0005580622819252312,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
474,192,0.080594003200531,0.0003003125311806798,0.0004650518822018057,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
475,256,0.10649819672107697,0.0005616895505227149,0.0004667195025831461,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
476,512,0.21530559659004211,0.001416233484633267,0.0004667195025831461,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
477,1024,0.4286516606807709,0.0026929774321615696,0.0004667195025831461,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
478,2048,,,,,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,CUDA out of memory. Tried to allocate 4.00 GiB (GPU 0; 10.91 GiB total capacity; 6.09 GiB already allocated; 3.09 GiB free; 7.02 GiB reserved in total by PyTorch)
479,4096,,,,,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,CUDA out of memory. Tried to allocate 4.01 GiB (GPU 0; 10.91 GiB total capacity; 8.09 GiB already allocated; 92.25 MiB free; 10.02 GiB reserved in total by PyTorch)
480,1,0.007567005697637796,0.002119123935699463,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
481,2,0.00704935472458601,0.0013401261530816555,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
482,3,0.007622418459504843,0.00016028563550207764,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
483,4,0.008639542385935783,0.002368856919929385,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
484,5,0.008565064519643784,0.0032405226957052946,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
485,6,0.008080837316811085,0.0015004982706159353,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
486,7,0.007598944939672947,0.00021652721625287086,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
487,8,0.007489270530641079,0.00014603184536099434,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
488,9,0.007721126079559326,0.00010924465459538624,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
489,10,0.007927696220576763,9.106847574003041e-05,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
490,11,0.008105059154331684,6.562500493600965e-05,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
491,12,0.008443840779364109,0.00016680631961207837,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
492,13,0.008562171831727028,7.329574145842344e-05,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
493,14,0.008694548159837723,6.844665040262043e-05,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
494,15,0.011102887801826,7.219173858175054e-05,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
495,16,0.0111902030184865,6.566844240296632e-05,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
496,24,0.013177054934203625,0.00011953987996093929,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
497,32,0.014964669942855835,0.00010902894427999854,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
498,64,0.02596091851592064,8.351881842827424e-05,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
499,96,0.03393843024969101,0.00017448516155127436,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
500,128,0.04401540756225586,0.0002056489756796509,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
501,160,0.05407959967851639,0.00015236808394547552,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
502,192,0.06350070238113403,0.00045911804772913456,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
503,256,0.0845431238412857,0.0005717225139960647,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
504,512,0.16961769759655,0.0009996258886530995,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
505,1024,0.33960944414138794,0.0024592361878603697,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
506,2048,,,,,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,CUDA out of memory. Tried to allocate 4.00 GiB (GPU 0; 10.91 GiB total capacity; 6.08 GiB already allocated; 3.09 GiB free; 7.02 GiB reserved in total by PyTorch)
507,4096,,,,,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,CUDA out of memory. Tried to allocate 4.01 GiB (GPU 0; 10.91 GiB total capacity; 8.08 GiB already allocated; 94.25 MiB free; 10.02 GiB reserved in total by PyTorch)
508,1,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
509,2,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
510,3,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
511,4,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
512,5,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
513,6,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
514,7,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
515,8,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
516,9,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
517,10,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
518,11,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
519,12,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
520,13,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
521,14,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
522,15,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
523,16,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
524,24,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
525,32,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
526,64,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
527,96,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
528,128,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
529,160,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
530,192,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
531,256,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
532,512,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
533,1024,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
534,2048,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/encoder.py"", line 29, in forward
    def forward(self, batch):
        return self.model.encode_bag_t(self.fft(batch).unsqueeze(1), normalize=True)[0]
                                       ~~~~~~~~ <--- HERE
  File ""/home/proger/boiler/boiler/mel.py"", line 39, in forward
        p = (self.n_fft - self.hop_length) // 2
        audio = F.pad(audio, (p, p), ""reflect"").squeeze(1)
        fft = torch.stft(
              ~~~~~~~~~~ <--- HERE
            audio,
            n_fft=self.n_fft,
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/functional.py"", line 515, in stft
        input = F.pad(input.view(extended_shape), (pad, pad), pad_mode)
        input = input.view(input.shape[-signal_dim:])
    return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore
           ~~~~~~~~ <--- HERE
                    normalized, onesided, return_complex)
RuntimeError: CUDA out of memory. Tried to allocate 4.00 GiB (GPU 0; 10.91 GiB total capacity; 6.09 GiB already allocated; 3.09 GiB free; 7.03 GiB reserved in total by PyTorch)
"
535,4096,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/encoder.py"", line 29, in forward
    def forward(self, batch):
        return self.model.encode_bag_t(self.fft(batch).unsqueeze(1), normalize=True)[0]
                                       ~~~~~~~~ <--- HERE
  File ""/home/proger/boiler/boiler/mel.py"", line 39, in forward
        p = (self.n_fft - self.hop_length) // 2
        audio = F.pad(audio, (p, p), ""reflect"").squeeze(1)
        fft = torch.stft(
              ~~~~~~~~~~ <--- HERE
            audio,
            n_fft=self.n_fft,
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/functional.py"", line 515, in stft
        input = F.pad(input.view(extended_shape), (pad, pad), pad_mode)
        input = input.view(input.shape[-signal_dim:])
    return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore
           ~~~~~~~~ <--- HERE
                    normalized, onesided, return_complex)
RuntimeError: CUDA out of memory. Tried to allocate 4.01 GiB (GPU 0; 10.91 GiB total capacity; 8.09 GiB already allocated; 90.25 MiB free; 10.03 GiB reserved in total by PyTorch)
"
536,1,0.006635402794927359,0.0009112380794249475,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
537,2,0.005904613994061947,0.00011290329712210223,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
538,3,0.005801095161587,0.00011132806685054675,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
539,4,0.0059803687036037445,0.00033202493796125054,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
540,5,0.006197109818458557,9.499877342022955e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
541,6,0.0065004280768334866,7.896142051322386e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
542,7,0.0066634975373744965,4.60188057331834e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
543,8,0.006861336529254913,5.419037552201189e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
544,9,0.007148934993892908,9.699120710138232e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
545,10,0.00731962313875556,4.762951357406564e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
546,11,0.00750613072887063,5.059050090494566e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
547,12,0.007745375391095877,3.700246088556014e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
548,13,0.007948474958539009,3.287138679297641e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
549,14,0.008121022954583168,5.713492282666266e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
550,15,0.010507133789360523,3.6684989026980475e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
551,16,0.010638564825057983,8.927057206165045e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
552,24,0.012561604380607605,3.9453108911402524e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
553,32,0.014315888285636902,3.1714873330201954e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
554,64,0.02527439594268799,0.00011906665895367041,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
555,96,0.03317071124911308,0.00012578771566040814,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
556,128,0.043134644627571106,0.0003187386319041252,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
557,160,0.05329391360282898,0.00029984061256982386,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
558,192,0.06247616559267044,0.0003127889649476856,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
559,256,0.08337046951055527,0.0005189081421121955,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
560,512,0.16840924322605133,0.0008656030404381454,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
561,1024,0.3317786753177643,0.0013376364950090647,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
562,2048,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/encoder.py"", line 29, in forward
    def forward(self, batch):
        return self.model.encode_bag_t(self.fft(batch).unsqueeze(1), normalize=True)[0]
                                       ~~~~~~~~ <--- HERE
  File ""/home/proger/boiler/boiler/mel.py"", line 39, in forward
        p = (self.n_fft - self.hop_length) // 2
        audio = F.pad(audio, (p, p), ""reflect"").squeeze(1)
        fft = torch.stft(
              ~~~~~~~~~~ <--- HERE
            audio,
            n_fft=self.n_fft,
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/functional.py"", line 515, in stft
        input = F.pad(input.view(extended_shape), (pad, pad), pad_mode)
        input = input.view(input.shape[-signal_dim:])
    return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore
           ~~~~~~~~ <--- HERE
                    normalized, onesided, return_complex)
RuntimeError: CUDA out of memory. Tried to allocate 4.00 GiB (GPU 0; 10.91 GiB total capacity; 6.08 GiB already allocated; 3.09 GiB free; 7.02 GiB reserved in total by PyTorch)
"
563,4096,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/encoder.py"", line 29, in forward
    def forward(self, batch):
        return self.model.encode_bag_t(self.fft(batch).unsqueeze(1), normalize=True)[0]
                                       ~~~~~~~~ <--- HERE
  File ""/home/proger/boiler/boiler/mel.py"", line 39, in forward
        p = (self.n_fft - self.hop_length) // 2
        audio = F.pad(audio, (p, p), ""reflect"").squeeze(1)
        fft = torch.stft(
              ~~~~~~~~~~ <--- HERE
            audio,
            n_fft=self.n_fft,
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/functional.py"", line 515, in stft
        input = F.pad(input.view(extended_shape), (pad, pad), pad_mode)
        input = input.view(input.shape[-signal_dim:])
    return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore
           ~~~~~~~~ <--- HERE
                    normalized, onesided, return_complex)
RuntimeError: CUDA out of memory. Tried to allocate 4.01 GiB (GPU 0; 10.91 GiB total capacity; 8.08 GiB already allocated; 92.25 MiB free; 10.02 GiB reserved in total by PyTorch)
"
