,batch_size,latency,latency_std,loss,loss_std,device,dtype,type,size,autocast,reason
0,1,0.020841378718614578,0.006813352461904287,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
1,2,0.01570582576096058,0.0008660655003041029,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
2,3,0.01837056875228882,0.0004997876822017133,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
3,4,0.023156339302659035,0.0006905961781740189,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
4,5,0.02948172390460968,0.00398474233224988,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
5,6,0.03305324912071228,0.0005183922476135194,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
6,7,0.03810693696141243,0.0009327299194410443,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
7,8,0.043578773736953735,0.0007499436032958329,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
8,9,0.0537731759250164,0.012734989635646343,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
9,10,0.05514238029718399,0.0012965016067028046,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
10,11,0.060407865792512894,0.0013676544185727835,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
11,12,0.06865982711315155,0.00816778838634491,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
12,13,0.07169634103775024,0.0007860113400965929,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
13,14,0.07658756524324417,0.0011594364186748862,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
14,15,0.08025012165307999,0.0011303649516776204,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
15,16,0.0917338952422142,0.015638507902622223,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
16,24,0.12741585075855255,0.0012773539638146758,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
17,32,0.17252583801746368,0.009320676326751709,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
18,64,0.38334542512893677,0.031125931069254875,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
19,1,0.01416034810245037,0.003581408178433776,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
20,2,0.01562655158340931,0.0006117124576121569,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
21,3,0.01828419789671898,0.000192718391190283,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
22,4,0.023072879761457443,0.00011911517503904179,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
23,5,0.028133749961853027,0.00010657106031430885,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
24,6,0.03261253982782364,0.00018527348584029824,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
25,7,0.038116030395030975,5.4709194955648854e-05,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
26,8,0.043513912707567215,0.00010354300320614129,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
27,9,0.04829064756631851,0.0001662800059420988,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
28,10,0.05577676370739937,0.005052379798144102,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
29,11,0.05965261533856392,0.0017330789705738425,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
30,12,0.06676846742630005,0.00792163796722889,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
31,13,0.07151616364717484,0.004198113922029734,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
32,14,0.07634621113538742,0.003756559221073985,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
33,15,0.08461697399616241,0.014820908196270466,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
34,16,0.08539339154958725,0.00029169319896027446,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
35,24,0.12937888503074646,0.0073157018050551414,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
36,32,0.17098399996757507,0.0020324799697846174,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
37,64,0.36423802375793457,0.007180002052336931,0.0,0.0,cpu,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
38,1,,,,,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
39,2,,,,,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
40,3,,,,,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
41,4,,,,,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
42,5,,,,,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
43,6,,,,,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
44,7,,,,,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
45,8,,,,,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
46,9,,,,,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
47,10,,,,,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
48,11,,,,,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
49,12,,,,,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
50,13,,,,,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
51,14,,,,,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
52,15,,,,,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
53,16,,,,,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
54,24,,,,,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
55,32,,,,,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
56,64,,,,,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
57,1,0.02526366338133812,0.02068859525024891,0.0,0.0,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
58,2,0.01670839823782444,0.0018680759239941835,0.0,0.0,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
59,3,0.016781270503997803,6.435550312744454e-05,0.0,0.0,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
60,4,0.021696897223591805,0.0001784733176464215,0.0,0.0,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
61,5,0.026543328538537025,0.00020223585306666791,0.0,0.0,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
62,6,0.03364545851945877,0.00761039974167943,0.0,0.0,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
63,7,0.03638298064470291,8.001641981536523e-05,0.0,0.0,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
64,8,0.04207063838839531,0.00037049356615170836,0.0,0.0,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
65,9,0.046731773763895035,0.00020712499099317938,0.0,0.0,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
66,10,0.051870863884687424,0.00023873311874922365,0.0,0.0,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
67,11,0.05745137855410576,0.00015200460620690137,0.0,0.0,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
68,12,0.06225170940160751,0.00023291837715078145,0.0,0.0,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
69,13,0.07305095344781876,0.012889904901385307,0.0,0.0,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
70,14,0.0736185684800148,0.0014896810753270984,0.0,0.0,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
71,15,0.0832468718290329,0.01065407320857048,0.0,0.0,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
72,16,0.08296229690313339,0.00027551763923838735,0.0,0.0,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
73,24,0.1301296353340149,0.014655505307018757,0.0,0.0,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
74,32,0.17492713034152985,0.001573176239617169,0.0,0.0,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
75,64,0.36979496479034424,0.009927425533533096,0.0,0.0,cpu,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
76,1,0.007696500979363918,0.0010482502402737737,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
77,2,0.007568282075226307,0.0002473590720910579,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
78,3,0.007515665143728256,0.00022403523325920105,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
79,4,0.007604668848216534,0.0002256090665468946,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
80,5,0.007569962181150913,0.0004019296320620924,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
81,6,0.007731886114925146,0.00023064327251631767,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
82,7,0.00796760804951191,0.0002190383820561692,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
83,8,0.008224551565945148,0.000238670822000131,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
84,9,0.008577248081564903,0.00021858156833332032,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
85,10,0.00893480610102415,0.0002147557243006304,0.0007517874473705888,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
86,11,0.0092410147190094,0.00021040475985500962,0.0006834430969320238,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
87,12,0.009521810337901115,0.00021989166270941496,0.000626489520072937,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
88,13,0.009853176772594452,0.00022528147383127362,0.0005782980006188154,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
89,14,0.010172205045819283,0.00020109927572775632,0.0005369909922592342,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
90,15,0.01057068444788456,0.00020795862656086683,0.0005011915927752852,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
91,16,0.01068037748336792,0.00019838994194287807,0.00046986714005470276,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
92,24,0.013405893929302692,0.00021275863400660455,0.0003132447600364685,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
93,32,0.015925606712698936,0.00020556754316203296,0.0008571762591600418,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
94,64,0.029741350561380386,0.00020580014097504318,0.0004285881295800209,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
95,96,0.041923537850379944,0.00023089318710844964,0.00036471709609031677,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
96,128,0.054534994065761566,0.0002247802185593173,0.00042672501876950264,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
97,160,0.06753328442573547,0.00028138290508650243,0.0003413800150156021,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
98,192,0.07927106320858002,0.00042448414023965597,0.0002844833361450583,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
99,256,0.10600633919239044,0.00047511770389974117,0.0002327954862266779,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
100,512,0.21272961795330048,0.0008496766677126288,0.0002327954862266779,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
101,1024,0.42522868514060974,0.0025647857692092657,0.0002327954862266779,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
102,2048,0.8509445190429688,0.0028711941558867693,0.0002327954862266779,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,ok
103,4096,,,,,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,True,CUDA out of memory. Tried to allocate 4.01 GiB (GPU 0; 10.91 GiB total capacity; 8.05 GiB already allocated; 2.05 GiB free; 8.07 GiB reserved in total by PyTorch)
104,1,0.007401070091873407,0.0022507256362587214,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
105,2,0.007560552563518286,0.0036096861585974693,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
106,3,0.006474238820374012,0.00027107674395665526,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
107,4,0.006465746555477381,0.0002732922148425132,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
108,5,0.00671838503330946,0.0002187199133913964,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
109,6,0.0069962493143975735,0.00014531848137266934,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
110,7,0.007214689161628485,0.00016547793347854167,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
111,8,0.007395411841571331,0.00018287512648385018,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
112,9,0.007589244749397039,0.00014950401964597404,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
113,10,0.007820612750947475,0.00016468536341562867,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
114,11,0.007990795187652111,0.00016708676412235945,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
115,12,0.008249757811427116,0.00016597153444308788,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
116,13,0.008453046903014183,0.00016055058222264051,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
117,14,0.00862034410238266,0.00020461826352402568,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
118,15,0.010999461635947227,0.00019648537272587419,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
119,16,0.011093519628047943,0.00019548131967894733,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
120,24,0.013061106204986572,0.00021513967658393085,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
121,32,0.014838764443993568,0.00015397222887258977,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
122,64,0.025850921869277954,0.0001922769151860848,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
123,96,0.03371444717049599,0.0001963758113561198,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
124,128,0.0439002588391304,0.00027154592680744827,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
125,160,0.05392008274793625,0.00032108183950185776,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
126,192,0.06299126148223877,0.0002700034820009023,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
127,256,0.08424580842256546,0.0001993625337490812,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
128,512,0.16931304335594177,0.0008115642121993005,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
129,1024,0.33579370379447937,0.0010180397657677531,0.0,0.0,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,ok
130,2048,,,,,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,CUDA out of memory. Tried to allocate 1.17 GiB (GPU 0; 10.91 GiB total capacity; 9.09 GiB already allocated; 732.25 MiB free; 9.40 GiB reserved in total by PyTorch)
131,4096,,,,,cuda,torch.float32,<class 'boiler.encoder.BagTopVQVAE'>,10124865,False,CUDA out of memory. Tried to allocate 4.01 GiB (GPU 0; 10.91 GiB total capacity; 8.05 GiB already allocated; 2.05 GiB free; 8.06 GiB reserved in total by PyTorch)
132,1,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
133,2,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
134,3,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
135,4,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
136,5,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
137,6,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
138,7,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
139,8,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
140,9,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
141,10,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
142,11,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
143,12,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
144,13,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
145,14,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
146,15,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
147,16,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
148,24,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
149,32,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
150,64,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
151,96,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
152,128,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
153,160,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
154,192,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
155,256,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
156,512,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
157,1024,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/quantize.py"", line 31, in forward
        if self.normalize_scale:
            target_norm = self.normalize_scale * torch.sqrt(torch.tensor([x0.size(3)], dtype=self.embedding0.dtype, device=self.embedding0.device))
            x = target_norm * x0 / x0.norm(dim=3, p=2, keepdim=True)
                                   ~~~~~~~ <--- HERE
            embedding = target_norm * self.embedding0 / self.embedding0.norm(dim=2, p=2, keepdim=True)
        else:
RuntimeError: false INTERNAL ASSERT FAILED at ""/pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp"":76, please report a bug to PyTorch. Tried to call KernelFunction::callBoxed() on a KernelFunction that can only be called with KernelFunction::call(). opname: aten::norm.ScalarOpt_dim If you're using mobile selective build please make sure to include all ops exported from `torch.jit.export_opnames(model)`.
"
158,2048,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/encoder.py"", line 29, in forward
    def forward(self, batch):
        return self.model.encode_bag_t(self.fft(batch).unsqueeze(1), normalize=True)[0]
                                       ~~~~~~~~ <--- HERE
  File ""/home/proger/boiler/boiler/mel.py"", line 39, in forward
        p = (self.n_fft - self.hop_length) // 2
        audio = F.pad(audio, (p, p), ""reflect"").squeeze(1)
        fft = torch.stft(
              ~~~~~~~~~~ <--- HERE
            audio,
            n_fft=self.n_fft,
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/functional.py"", line 515, in stft
        input = F.pad(input.view(extended_shape), (pad, pad), pad_mode)
        input = input.view(input.shape[-signal_dim:])
    return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore
           ~~~~~~~~ <--- HERE
                    normalized, onesided, return_complex)
RuntimeError: CUDA out of memory. Tried to allocate 4.00 GiB (GPU 0; 10.91 GiB total capacity; 6.05 GiB already allocated; 3.07 GiB free; 7.04 GiB reserved in total by PyTorch)
"
159,4096,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,True,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/encoder.py"", line 29, in forward
    def forward(self, batch):
        return self.model.encode_bag_t(self.fft(batch).unsqueeze(1), normalize=True)[0]
                                       ~~~~~~~~ <--- HERE
  File ""/home/proger/boiler/boiler/mel.py"", line 39, in forward
        p = (self.n_fft - self.hop_length) // 2
        audio = F.pad(audio, (p, p), ""reflect"").squeeze(1)
        fft = torch.stft(
              ~~~~~~~~~~ <--- HERE
            audio,
            n_fft=self.n_fft,
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/functional.py"", line 515, in stft
        input = F.pad(input.view(extended_shape), (pad, pad), pad_mode)
        input = input.view(input.shape[-signal_dim:])
    return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore
           ~~~~~~~~ <--- HERE
                    normalized, onesided, return_complex)
RuntimeError: CUDA out of memory. Tried to allocate 4.01 GiB (GPU 0; 10.91 GiB total capacity; 8.05 GiB already allocated; 76.25 MiB free; 10.04 GiB reserved in total by PyTorch)
"
160,1,0.006306530442088842,0.0013601335231214762,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
161,2,0.005726686213165522,0.0002138768177246675,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
162,3,0.005772375501692295,0.00011555911623872817,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
163,4,0.005855754017829895,9.463341848459095e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
164,5,0.006312026642262936,0.0007395416614599526,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
165,6,0.00644004438072443,7.359820301644504e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
166,7,0.006607575807720423,5.2486568165477365e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
167,8,0.006807591766119003,5.2726227295352146e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
168,9,0.00701823178678751,4.2797328205779195e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
169,10,0.007237475365400314,4.2003779526567087e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
170,11,0.007628044579178095,7.349601219175383e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
171,12,0.007720470428466797,6.272911559790373e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
172,13,0.007890892215073109,3.247323547839187e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
173,14,0.008057482540607452,3.565442602848634e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
174,15,0.010456702671945095,5.566624895436689e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
175,16,0.010519750416278839,3.685356568894349e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
176,24,0.012468039989471436,3.1004896300146356e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
177,32,0.01422640960663557,3.2379964977735654e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
178,64,0.02507047913968563,8.605448965681717e-05,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
179,96,0.03291049227118492,0.00015137532318476588,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
180,128,0.04295676201581955,0.00028905284125357866,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
181,160,0.052866626530885696,0.0002695087459869683,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
182,192,0.062002260237932205,0.0003196168108843267,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
183,256,0.08284125477075577,0.0004898254992440343,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
184,512,0.16691268980503082,0.0006570189143531024,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
185,1024,0.3308119773864746,0.0019622906111180782,0.0,0.0,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,ok
186,2048,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/encoder.py"", line 29, in forward
    def forward(self, batch):
        return self.model.encode_bag_t(self.fft(batch).unsqueeze(1), normalize=True)[0]
                                       ~~~~~~~~ <--- HERE
  File ""/home/proger/boiler/boiler/mel.py"", line 39, in forward
        p = (self.n_fft - self.hop_length) // 2
        audio = F.pad(audio, (p, p), ""reflect"").squeeze(1)
        fft = torch.stft(
              ~~~~~~~~~~ <--- HERE
            audio,
            n_fft=self.n_fft,
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/functional.py"", line 515, in stft
        input = F.pad(input.view(extended_shape), (pad, pad), pad_mode)
        input = input.view(input.shape[-signal_dim:])
    return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore
           ~~~~~~~~ <--- HERE
                    normalized, onesided, return_complex)
RuntimeError: CUDA out of memory. Tried to allocate 4.00 GiB (GPU 0; 10.91 GiB total capacity; 6.05 GiB already allocated; 3.08 GiB free; 7.04 GiB reserved in total by PyTorch)
"
187,4096,,,,,cuda,torch.float32,<class 'torch.jit._script.RecursiveScriptModule'>,10124865,False,"The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File ""/home/proger/boiler/boiler/encoder.py"", line 29, in forward
    def forward(self, batch):
        return self.model.encode_bag_t(self.fft(batch).unsqueeze(1), normalize=True)[0]
                                       ~~~~~~~~ <--- HERE
  File ""/home/proger/boiler/boiler/mel.py"", line 39, in forward
        p = (self.n_fft - self.hop_length) // 2
        audio = F.pad(audio, (p, p), ""reflect"").squeeze(1)
        fft = torch.stft(
              ~~~~~~~~~~ <--- HERE
            audio,
            n_fft=self.n_fft,
  File ""/home/proger/.local/lib/python3.8/site-packages/torch/functional.py"", line 515, in stft
        input = F.pad(input.view(extended_shape), (pad, pad), pad_mode)
        input = input.view(input.shape[-signal_dim:])
    return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore
           ~~~~~~~~ <--- HERE
                    normalized, onesided, return_complex)
RuntimeError: CUDA out of memory. Tried to allocate 4.01 GiB (GPU 0; 10.91 GiB total capacity; 8.05 GiB already allocated; 78.25 MiB free; 10.04 GiB reserved in total by PyTorch)
"
